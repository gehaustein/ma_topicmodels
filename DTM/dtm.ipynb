{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import timeit\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',filename=\"model.log\", level=logging.INFO)\n",
    "import random\n",
    "from operator import itemgetter\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import ldaseqmodel\n",
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_no = 42\n",
    "n_topics = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/complete_data_by_speech.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df = df.sort_values([\"date\", \"intervention_id\"])\n",
    "filter_df = filter_df[[\"date\",\"intervention_id\",\"text\",\"mep_id\",\"full_name\",\"role\",\"is_mep\",\"langdetect\",\"langid\"]]\n",
    "filter_df[\"lang_checkup\"] = np.where(filter_df[\"langdetect\"] == filter_df[\"langid\"], True, False)\n",
    "filter_df = filter_df[filter_df[\"langdetect\"]==\"en\"]\n",
    "filter_df = filter_df[filter_df[\"is_mep\"]==True]\n",
    "filter_df[\"date\"] = pd.to_datetime(filter_df[\"date\"])\n",
    "filter_df[\"year\"] = filter_df[\"date\"].dt.year\n",
    "filter_df = filter_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../LDA/corpus\", \"r\") as fp:\n",
    "    corpus = json.load(fp)\n",
    "\n",
    "with open(\"../LDA/data_lemmatized\", \"r\") as fp:\n",
    "    data_lemmatized = json.load(fp)\n",
    "\n",
    "id2word = corpora.Dictionary(data_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed_no)\n",
    "random_training_index = random.sample(range(0,len(corpus),1), int(len(corpus)/10))\n",
    "random_training_index.sort()\n",
    "random_training_index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_corpus = [corpus[index] for index in random_training_index]\n",
    "print(len(corpus), len(training_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = filter_df[\"year\"].tolist()\n",
    "len(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_date_list = [date_list[index] for index in random_training_index]\n",
    "len(training_date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = []\n",
    "\n",
    "for i in range(len(training_corpus)): #bow_corpus is the corpus\n",
    "    if len(training_corpus[i])==0: #check for empty document\n",
    "        remove_list.append(i) #if there is any empty document then print the index of that document\n",
    "\n",
    "len(remove_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in sorted(remove_list, reverse=True):\n",
    "    del training_corpus[index]\n",
    "\n",
    "len(training_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in sorted(remove_list, reverse=True):\n",
    "    del training_date_list[index]\n",
    "\n",
    "len(training_date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueyears, time_slice = np.unique(training_date_list, return_counts=True) \n",
    "time_slice = time_slice.tolist()\n",
    "time_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(time_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_lda_model = ldaseqmodel.LdaSeqModel(corpus=training_corpus,\n",
    "                                        id2word=id2word,\n",
    "                                        time_slice=time_slice,\n",
    "                                        num_topics=n_topics,\n",
    "                                        random_state=seed_no,\n",
    "                                        passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_lda_model.save(f\"models_{seed_no}/dtm_model_{n_topics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_load = ldaseqmodel.LdaSeqModel.load(f\"models_{seed_no}/lda_model_{n_topics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dict = dtm_load.print_topic_times(topic=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_df = pd.DataFrame(columns=[\"term\"])\n",
    "\n",
    "for i in range(0,23,1):\n",
    "    temp_df = pd.DataFrame(topic_dict[i], columns = [\"term\", str(uniqueyears[i])])\n",
    "    yearly_df = pd.merge(yearly_df, temp_df, on=\"term\", how=\"outer\").set_index(\"term\", drop=True)\n",
    "\n",
    "yearly_df = yearly_df.dropna().transpose()\n",
    "\n",
    "yearly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_df.to_csv(\"visualisation/yearly_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_df.plot.line()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d99cafe4c174b2b44bd35f69a9f9f4db6ae957380b95445e310397cf4491890f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ma_condaenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
